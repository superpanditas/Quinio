{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "1-6RwZrNX_Lz"
      ],
      "authorship_tag": "ABX9TyPkKfGn+N/JhpFFPZOZUzZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superpanditas/Quinio/blob/main/%5BForecasting_Units%5D_By_Stores_and_Items.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0 - Getting Started\n",
        "\n",
        "**Business Problem:** A company is getting stock outs due to don't have enought ...\n",
        "\n",
        "Help the Tech and Product Team to forecast units sold\n",
        "The approach followed is begin to forecast units sold by all company, after by stores and finally by items. The goal is to forecast units sold by ...\n",
        "\n"
      ],
      "metadata": {
        "id": "hgmHcORzloR7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS3c9_oT0Tlx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import Libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# define the custom style function\n",
        "def set_custom_style(df):\n",
        "  return (df.style\n",
        "          .format(precision='2', decimal='.', thousands=',')\n",
        "          .set_table_styles({\n",
        "                  '': [{'selector': 'td', 'props': [('background-color', '#f5f5f5')]}]\n",
        "              })\n",
        "          .set_properties(**{\n",
        "            'font-size':'14px',\n",
        "            'font-family':'Arial',\n",
        "          })\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Data\n",
        "df = pd.read_csv('/content/Productlevel_Sales_Transactions_Dataset_Weekly.csv')\n",
        "df_styled = set_custom_style(df.head(5))\n",
        "df_styled"
      ],
      "metadata": {
        "id": "wTSV4bs_0d4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Data Cleaning\n"
      ],
      "metadata": {
        "id": "1-6RwZrNX_Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Reshaping DataFrame\n",
        "\n",
        "'''\n",
        "Transform the DataFrame to adjust it to analysis, where each row represents a single store,\n",
        "a weekly and the units sold\n",
        "'''\n",
        "\n",
        "id_vars = ['Scode', 'Pcode', 'Price']\n",
        "value_var = ['Wk'+str(i) for i in range(0,104)]\n",
        "var_name = 'weekly'\n",
        "value_name = 'units'\n",
        "\n",
        "# rename columns\n",
        "new_col_names = ['store', 'item', 'price', 'weekly', 'units']\n",
        "\n",
        "# compute melt function to change the data format\n",
        "sales = df.melt(id_vars=id_vars, value_vars=value_var, var_name=var_name, value_name=value_name)\n",
        "sales.columns = new_col_names"
      ],
      "metadata": {
        "id": "a9l3htlN39hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Duplicate Values\n",
        "\n",
        "'''\n",
        "The dataframe has different prices for some values ​​['weekly', 'store', 'price'], ...\n",
        "for simplicity, we will sum all units by 'weekly', 'store' and 'price' columns and omit the unit price column\n",
        "'''\n",
        "\n",
        "sales = sales.groupby(['weekly', 'store', 'item'])['units'].sum().reset_index()"
      ],
      "metadata": {
        "id": "ECaJ30wXIAJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weekly Dates\n",
        "\n",
        "'''\n",
        "It's more useful have real weekly dates, so we're going to add a column of dates\n",
        "'''\n",
        "\n",
        "# initialize of first weekly date (Note that weeks start on sundays)\n",
        "init_week = pd.to_datetime('2023-01-07')\n",
        "\n",
        "# create a function to compute mapping from weekly column to weekly dates according to the number of week\n",
        "def calculate_date(weekly):\n",
        "  week_number = int(weekly[2:])\n",
        "  return init_week + timedelta(weeks=week_number)\n",
        "\n",
        "sales['weekly_date'] = sales['weekly'].apply(calculate_date)"
      ],
      "metadata": {
        "id": "bT4spdxrDm5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weekly and Monthly (DataFrame)\n",
        "\n",
        "'''\n",
        "There'are multiple prices for some items in the same timeframe, so for simplicity\n",
        "we're going to eliminate 'price' column and sum units.\n",
        "'''\n",
        "\n",
        "# create the dataframe called 'weekly_sales_by_store'\n",
        "weekly_sales_by_store = sales.copy()\n",
        "\n",
        "# drop \"weekly\" column\n",
        "weekly_sales_by_store = weekly_sales_by_store.drop('weekly', axis=1)\n",
        "\n",
        "# data grouped\n",
        "weekly_sales_by_store = weekly_sales_by_store.groupby(['weekly_date', 'store', 'item'])['units'].sum().reset_index()\n",
        "\n",
        "# set index 'weekly_date' column\n",
        "weekly_sales_by_store = weekly_sales_by_store.set_index('weekly_date')\n",
        "weekly_sales_by_store.index = pd.to_datetime(weekly_sales_by_store.index)\n",
        "\n",
        "# -------\n",
        "\n",
        "# create the dataframe called 'monthly_sales_by_store' using resample function\n",
        "\n",
        "monthly_sales_by_store = weekly_sales_by_store.copy()\n",
        "# compute resample function\n",
        "monthly_sales_by_store = monthly_sales_by_store.groupby(['store', 'item']).resample('M')['units'].sum().reset_index()\n",
        "\n",
        "# set and rename index 'weekly_date' column to 'monthly date'\n",
        "monthly_sales_by_store = monthly_sales_by_store.set_index('weekly_date')\n",
        "monthly_sales_by_store = monthly_sales_by_store.rename_axis('monthly_date')\n"
      ],
      "metadata": {
        "id": "lYmXURl-dBtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - Data Understanding\n",
        "\n",
        "Analysis Highlights:\n",
        "  \n",
        "  Weekly Units (From Jan to Oct): 2023 vs 2024\n",
        "    - The units sold WoW keep similar behavior between Jan-Oct but Nov-Dec ..."
      ],
      "metadata": {
        "id": "KCzK-rNfOAOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Monthly and Weekly Stats (DataFrame)\n",
        "# create 'df_monthly' and 'df_weekly' dataframe to calculate stats\n",
        "df_monthly = monthly_sales_by_store.copy()\n",
        "df_weekly = weekly_sales_by_store.copy()\n",
        "\n",
        "# add 'year' and 'month' column\n",
        "df_monthly['year'] = df_monthly.index.year\n",
        "df_monthly['month'] = df_monthly.index.month\n",
        "\n",
        "df_weekly['year'] = df_weekly.index.year\n",
        "df_weekly['month'] = df_weekly.index.month\n",
        "\n",
        "# -------\n",
        "# create 'monthly_stats' dataframe\n",
        "monthly_stats = df_monthly.groupby(['monthly_date']).agg({\n",
        "    'units': [lambda x: np.percentile(x, 25), 'median', lambda x: np.percentile(x, 95), 'sum', 'max'],\n",
        "    'item': 'nunique'\n",
        "})\n",
        "\n",
        "monthly_stats.columns = ['25th_perc', 'median', '95th_perc', 'units', 'max', 'total_items']\n",
        "monthly_stats['pct_change'] = np.round(100 * monthly_stats['units'].pct_change(12),2)\n",
        "monthly_stats['diff'] = np.round(monthly_stats['units'].diff(12))\n",
        "\n",
        "# -------\n",
        "# create 'monthly_stats_by_store' dataframe\n",
        "monthly_stats_by_store = df_monthly.groupby(['monthly_date', 'store']).agg({\n",
        "    'units': [lambda x: np.percentile(x, 25), 'median', lambda x: np.percentile(x, 95), 'sum', 'max'],\n",
        "    'item': 'nunique'\n",
        "})\n",
        "\n",
        "monthly_stats_by_store.columns = ['25th_perc', 'median', '95th_perc', 'units', 'max', 'total_items']\n",
        "monthly_stats_by_store['pct_change'] = np.round(100 * monthly_stats_by_store.groupby('store')['units'].pct_change(12),2)\n",
        "monthly_stats_by_store['diff'] = np.round(monthly_stats_by_store.groupby('store')['units'].diff(12))\n",
        "\n",
        "monthly_stats_by_store = monthly_stats_by_store.reset_index('store')\n",
        "\n",
        "# -------\n",
        "# create 'weekly_stats' dataframe\n",
        "weekly_stats = df_weekly.groupby(['weekly_date']).agg({\n",
        "    'units': [lambda x: np.percentile(x, 25), 'median', lambda x: np.percentile(x, 95), 'sum', 'max'],\n",
        "    'item': 'nunique'\n",
        "})\n",
        "\n",
        "weekly_stats.columns = ['25th_perc', 'median', '95th_perc', 'units', 'max', 'total_items']\n",
        "weekly_stats['pct_change'] = np.round(100 * weekly_stats['units'].pct_change(52),2)\n",
        "weekly_stats['diff'] = np.round(weekly_stats['units'].diff(52))\n",
        "\n",
        "# -------\n",
        "# create 'weekly_stats_by_store' dataframe\n",
        "weekly_stats_by_store = df_weekly.groupby(['weekly_date', 'store']).agg({\n",
        "    'units': [lambda x: np.percentile(x, 25), 'median', lambda x: np.percentile(x, 95), 'sum', 'max', 'mean'],\n",
        "    'item': 'nunique'\n",
        "})\n",
        "\n",
        "weekly_stats_by_store.columns = ['25th_perc', 'median', '95th_perc', 'units', 'max', 'total_items', 'mean']\n",
        "weekly_stats_by_store['pct_change'] = np.round(100 * weekly_stats_by_store.groupby('store')['units'].pct_change(52),2)\n",
        "weekly_stats_by_store['diff'] = np.round(weekly_stats_by_store.groupby('store')['units'].diff(52))\n",
        "\n",
        "weekly_stats_by_store = weekly_stats_by_store.reset_index('store')\n",
        "\n",
        "# -------\n",
        "# create 'weekly_stats_by_store_and_item' dataframe\n",
        "weekly_stats_by_store_and_item = df_weekly.groupby(['weekly_date', 'store', 'item']).agg({\n",
        "    'units': 'sum'\n",
        "})\n",
        "\n",
        "weekly_stats_by_store_and_item.columns = ['units']\n",
        "weekly_stats_by_store_and_item['pct_change'] = np.round(100 * weekly_stats_by_store_and_item.groupby(['store', 'item'])['units'].pct_change(52),2)\n",
        "weekly_stats_by_store_and_item['diff'] = np.round(weekly_stats_by_store_and_item.groupby(['store', 'item'])['units'].diff(52))\n",
        "weekly_stats_by_store_and_item['lag_52'] = np.round(weekly_stats_by_store_and_item.groupby(['store', 'item'])['units'].shift(52))\n",
        "\n",
        "weekly_stats_by_store_and_item = weekly_stats_by_store_and_item.reset_index('store')\n",
        "weekly_stats_by_store_and_item = weekly_stats_by_store_and_item.reset_index('item')"
      ],
      "metadata": {
        "id": "4yKWUA3w4t-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timeseries_plot(df, date_format, year_one, year_two, start_month, end_month, y_lim, title='weekly'):\n",
        "\n",
        "  start_date_one = year_one + '-' + start_month\n",
        "  end_date_one = year_one + '-' + end_month\n",
        "\n",
        "  start_date_two = year_two + '-' + start_month\n",
        "  end_date_two = year_two + '-' + end_month\n",
        "\n",
        "\n",
        "  title_one = title + ' ' + 'Units Sold (2023): 25th, 50th and 95th Percentile'\n",
        "  title_two = title + ' ' + 'Units Sold (2024): 25th, 50th and 95th Percentile'\n",
        "\n",
        "  y_lim_one = y_lim\n",
        "  y_lim_two = y_lim\n",
        "\n",
        "  date_format = date_format\n",
        "  stats = df\n",
        "\n",
        "  # -------\n",
        "\n",
        "  fig, ax = plt.subplots(2, 1, sharey=False, figsize=(15, 14))\n",
        "\n",
        "  ax[0].set_title(title_one)\n",
        "  ax[0].plot(stats[start_date_one:end_date_one].index.strftime(date_format),\n",
        "            stats[start_date_one:end_date_one]['median'])\n",
        "  ax[0].plot(stats[start_date_one:end_date_one].index.strftime(date_format),\n",
        "            stats[start_date_one:end_date_one]['25th_perc'],\n",
        "            linestyle='--')\n",
        "  ax[0].plot(stats[start_date_one:end_date_one].index.strftime(date_format),\n",
        "            stats[start_date_one:end_date_one]['95th_perc'],\n",
        "            linestyle='--')\n",
        "  ax[0].set_ylim(0, y_lim_one)\n",
        "  ax[0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "  ax[1].set_title(title_two)\n",
        "  ax[1].plot(stats[start_date_two:end_date_two].index.strftime(date_format),\n",
        "            stats[start_date_two:end_date_two]['median'])\n",
        "  ax[1].plot(stats[start_date_two:end_date_two].index.strftime(date_format),\n",
        "            stats[start_date_two:end_date_two]['25th_perc'],\n",
        "            linestyle='--')\n",
        "  ax[1].plot(stats[start_date_two:end_date_two].index.strftime(date_format),\n",
        "            stats[start_date_two:end_date_two]['95th_perc'],\n",
        "            linestyle='--')\n",
        "  ax[1].set_ylim(0, y_lim_two)\n",
        "  ax[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "hpFKK8FhhCnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Weekly Units Sold (Jan-Nov): 2023 vs 2024\n",
        "timeseries_plot(weekly_stats, '%b-%d', '2023', '2024', '01-01', '11-25', 160, 'Weekly')"
      ],
      "metadata": {
        "id": "EPPfjxkDajQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weekly Units Sold (Nov-Dic): 2023 vs 2024\n",
        "timeseries_plot(weekly_stats, '%b-%d', '2023', '2024', '11-23', '12-31', 4000, 'Weekly')"
      ],
      "metadata": {
        "id": "BIbcYoLWUZW9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weekly Units Sold: YoY Pct Change (%)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
        "\n",
        "ax[0].set_title('Weekly Units (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[0].plot(weekly_stats['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[0].tick_params(axis='x', rotation=90)\n",
        "ax[0].set_ylim(0, 5)\n",
        "\n",
        "ax[1].set_title('Weekly Units Sold (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[1].plot(weekly_stats['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HK91FwUJR2jL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weekly_stats_by_store_one = weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store1']\n",
        "weekly_stats_by_store_two = weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store2']\n",
        "weekly_stats_by_store_three = weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store3']\n",
        "weekly_stats_by_store_four = weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store4']\n",
        "weekly_stats_by_store_five = weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store5']\n",
        "\n",
        "# weekly_stats_by_store_and_item_one = weekly_stats_by_store_and_item[weekly_stats_by_store_and_item['store'] == 'Store2']\n",
        "# weekly_stats_by_store_and_item_one[weekly_stats_by_store_and_item_one['lag_52'] == 0]\n",
        "\n",
        "data = weekly_stats_by_store_and_item[weekly_stats_by_store_and_item['lag_52'] == 0]\n",
        "data_agg = data.groupby(['weekly_date', 'store'])['units'].sum().reset_index()\n",
        "data_agg = data_agg.set_index('weekly_date')\n",
        "\n",
        "# data_agg.head()\n",
        "store1 = weekly_stats_by_store_and_item[(weekly_stats_by_store_and_item['lag_52'] > 0) & (weekly_stats_by_store_and_item['store'] == 'Store1') & (weekly_stats_by_store_and_item.index == '2024-07-06')]\n",
        "store1.sort_values('diff', ascending=False).head(50)\n",
        "\n",
        "# data_agg[data_agg['store'] == 'Store1']['units'].plot()"
      ],
      "metadata": {
        "id": "esLnnok8oa0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weekly Units Sold By Store: YoY Pct Change (%)\n",
        "fig, ax = plt.subplots(5, 2, figsize=(20, 35))\n",
        "\n",
        "# ------- Store 1\n",
        "ax[0,0].set_title('Weekly Units Sold - Store 1 (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[0,0].plot(weekly_stats_by_store_one['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats_by_store_one['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[0,0].tick_params(axis='x', rotation=90)\n",
        "# ax[0,0].set_ylim(0, 5)\n",
        "\n",
        "ax[0,1].set_title('Weekly Units Sold - Store 1 (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[0,1].plot(weekly_stats_by_store_one['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats_by_store_one['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[0,1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# ------- Store 2\n",
        "ax[1,0].set_title('Weekly Units Sold - Store 2 (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[1,0].plot(weekly_stats_by_store_two['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats_by_store_two['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[1,0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "ax[1,1].set_title('Weekly Units Sold - Store 2 (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[1,1].plot(weekly_stats_by_store_two['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats_by_store_two['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[1,1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# ------- Store 3\n",
        "ax[2,0].set_title('Weekly Units Sold - Store 3 (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[2,0].plot(weekly_stats_by_store_three['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats_by_store_three['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[2,0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "ax[2,1].set_title('Weekly Units Sold - Store 3 (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[2,1].plot(weekly_stats_by_store_three['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats_by_store_three['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[2,1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# ------- Store 4\n",
        "ax[3,0].set_title('Weekly Units Sold - Store 4 (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[3,0].plot(weekly_stats_by_store_four['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats_by_store_four['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[3,0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "ax[3,1].set_title('Weekly Units Sold - Store 4 (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[3,1].plot(weekly_stats_by_store_four['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats_by_store_four['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[3,1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# ------- Store 5\n",
        "ax[4,0].set_title('Weekly Units Sold - Store 5 (Jan-Nov): YoY Pct Change (%)')\n",
        "ax[4,0].plot(weekly_stats_by_store_five['2024-01-01':'2024-11-18'].index.strftime('%b-%d'), weekly_stats_by_store_five['2024-01-01':'2024-11-18']['pct_change'])\n",
        "ax[4,0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "ax[4,1].set_title('Weekly Units Sold - Store 5 (Nov-Dic): YoY Pct Change (%)')\n",
        "ax[4,1].plot(weekly_stats_by_store_five['2024-11-18':'2024-12-31'].index.strftime('%b-%d'), weekly_stats_by_store_five['2024-11-18':'2024-12-31']['pct_change'])\n",
        "ax[4,1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lnSDdVGXoBBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_plot(weekly_stats_by_store[weekly_stats_by_store['store'] == 'Store3'], '%b-%d', '2023', '2024', '01-01', '11-25', 700, 'Weekly')"
      ],
      "metadata": {
        "id": "NcmG-wyatEwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 - Feauture Engineering\n",
        "\n",
        "- Lags\n",
        "- Seasonality\n",
        "- Month\n",
        "- ..."
      ],
      "metadata": {
        "id": "ehdUUr0DtuEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------\n",
        "'''num_lags = 13\n",
        "window_size = 3\n",
        "\n",
        "for lag_n in range(7, num_lags):\n",
        "  # create the lag_12 column by grouping by store\n",
        "  company_sales_by_monthly[f'lag_{lag_n}'] = company_sales_by_monthly.groupby(['store'])['units'].shift(lag_n)\n",
        "\n",
        "  # compute EWMA for the 'units' column and use it to fill NaN values in the 'lag_12' column\n",
        "  ewma_filled_values = company_sales_by_monthly.groupby('store')['units'].transform(lambda x: x.ewm(span=window_size, adjust=False).mean())\n",
        "\n",
        "  # fill NaN values in the 'lag_12' column using the computed EWMA values\n",
        "  company_sales_by_monthly[f'lag_{lag_n}'] = company_sales_by_monthly[f'lag_{lag_n}'].fillna(np.round(ewma_filled_values,2))'''\n",
        "# -------\n"
      ],
      "metadata": {
        "id": "0cix-AmM8HdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autocorrelation Plot\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "plot_pacf(weekly_stats_by_store_and_item[(weekly_stats_by_store_and_item['item'] == 'SKU1') & (weekly_stats_by_store_and_item['store'] == 'Store2')].units, lags=52, alpha=0.05)\n",
        "pacf(weekly_stats_by_store_and_item[(weekly_stats_by_store_and_item['item'] == 'SKU1') & (weekly_stats_by_store_and_item['store'] == 'Store2')].units, nlags=52)\n",
        "# weekly_stats_by_store_and_item[(weekly_stats_by_store_and_item['item'] == 'SKU1') & (weekly_stats_by_store_and_item['store'] == 'Store1')]"
      ],
      "metadata": {
        "id": "Ek4kqdZHE1or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Lags Feature\n",
        "\n",
        "lags = [1, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 50, 51, 52]\n",
        "\n",
        "# compute lags\n",
        "for lag_n in lags:\n",
        "  weekly_sales_by_store[f'lag_{lag_n}'] = weekly_sales_by_store.groupby(['store', 'item'])['units'].shift(lag_n)\n",
        "\n",
        "# fill NaN values\n",
        "weekly_sales_by_store['lag_52'] = weekly_sales_by_store['lag_52'].fillna(weekly_sales_by_store['lag_1'])\n",
        "weekly_sales_by_store['lag_51'] = weekly_sales_by_store['lag_51'].fillna(weekly_sales_by_store['lag_2'])\n",
        "weekly_sales_by_store['lag_50'] = weekly_sales_by_store['lag_50'].fillna(weekly_sales_by_store['lag_3'])\n",
        "\n",
        "# weekly_sales_by_store[(weekly_sales_by_store['store'] == 'Store5') & (weekly_sales_by_store['item'] == 'SKU99')].head(54)"
      ],
      "metadata": {
        "id": "ssnNLfTs0ZZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Peak Weeks Feauture\n",
        "\n",
        "# add seasonal pattern column\n",
        "weekly_sales_by_store.loc[weekly_sales_by_store.index.isin([\n",
        "    '2023-12-02',\n",
        "    '2023-12-09',\n",
        "    '2023-12-16',\n",
        "    '2023-12-23',\n",
        "    '2024-11-23',\n",
        "    '2024-11-30',\n",
        "    '2024-12-07',\n",
        "    '2024-12-14']), 'is_peak_season'] = 1\n",
        "\n",
        "weekly_sales_by_store.loc[~weekly_sales_by_store.index.isin([\n",
        "    '2023-12-02',\n",
        "    '2023-12-09',\n",
        "    '2023-12-16',\n",
        "    '2023-12-23',\n",
        "    '2024-11-23',\n",
        "    '2024-11-30',\n",
        "    '2024-12-07',\n",
        "    '2024-12-14']), 'is_peak_season'] = 0"
      ],
      "metadata": {
        "id": "TknKvA93asr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Timeframe Feature\n",
        "# cast index as DatetimeIndex\n",
        "weekly_sales_by_store.index = pd.to_datetime(weekly_sales_by_store.index)\n",
        "\n",
        "# add week column\n",
        "weekly_sales_by_store['week_number'] = weekly_sales_by_store.index.to_series().dt.isocalendar().week\n",
        "\n",
        "# sort the DatetimeIndex\n",
        "weekly_sales_by_store = weekly_sales_by_store.sort_index()"
      ],
      "metadata": {
        "id": "yQinin1S0_Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# add difference from 12 months ago\n",
        "company_sales_by_monthly['diff_12'] = company_sales_by_monthly.groupby('store')['units'].diff(12)\n",
        "\n",
        "# compute diff_1 for the 'units' column and use it to fill NaN values in the 'diff_12' column\n",
        "diff_filled_values = company_sales_by_monthly.groupby('store')['units'].transform(lambda x: x.diff(1))\n",
        "\n",
        "# fill NaN values in the 'diff_12' column using the computed diff_1 values\n",
        "company_sales_by_monthly['diff_12'] = company_sales_by_monthly['diff_12'].fillna(np.round(diff_filled_values,2))\n",
        "'''"
      ],
      "metadata": {
        "id": "fBqwWJBiNpR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Encode categorical variables\n",
        "# Combine 'store' and 'item' into a single column\n",
        "weekly_sales_by_store['store_item'] = weekly_sales_by_store['store'] + '_' + weekly_sales_by_store['item']\n",
        "\n",
        "weekly_sales_by_store = weekly_sales_by_store[weekly_sales_by_store['store'].isin(['Store2', 'Store3', 'Store4', 'Store5'])]\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "weekly_sales_by_store['store_item_encoded'] = le.fit_transform(weekly_sales_by_store['store_item'])\n",
        "weekly_sales_by_store.head()\n"
      ],
      "metadata": {
        "id": "PPDRu3QHM57m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 - Data Modeling"
      ],
      "metadata": {
        "id": "P6hWbI-aFD9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#weekly_sales_by_store = weekly_sales_by_store[weekly_sales_by_store['store'] == 'Store2']\n",
        "weekly_sales_by_store = weekly_sales_by_store.reset_index()\n",
        "weekly_sales_by_store = weekly_sales_by_store.set_index(['weekly_date', 'store', 'item'])\n",
        "weekly_sales_by_store.head()"
      ],
      "metadata": {
        "id": "SJZlfb2SY6rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "data = weekly_sales_by_store.drop(['lag_1',\n",
        "                                   'lag_2',\n",
        "                                   'lag_3',\n",
        "                                   'store_item'], axis=1)\n",
        "\n",
        "FEATURE = ['lag_50',\n",
        "           'lag_51',\n",
        "           'lag_52',\n",
        "           'lag_14',\n",
        "           'lag_13',\n",
        "           'lag_12',\n",
        "           'lag_11',\n",
        "           'lag_10',\n",
        "           'lag_9',\n",
        "           'lag_8',\n",
        "           'lag_7',\n",
        "           'is_peak_season',\n",
        "           'week_number',\n",
        "           'store_item_encoded']\n",
        "\n",
        "TARGET = ['units']\n",
        "\n",
        "# weekly_sales_by_monthly = weekly_sales_by_monthly.set_index('weekly_date')\n",
        "data_train = data['2023-11-01':'2024-11-16']\n",
        "data_test = data['2024-11-16':'2024-12-31']\n",
        "\n",
        "x_train, y_train = data_train[FEATURE], data_train[TARGET]\n",
        "\n",
        "x_test, y_test = data_test[FEATURE], data_test[TARGET]\n",
        "\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'lambda': [0, 1],\n",
        "    'alpha': [0, 1]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(),\n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=50,\n",
        "                                   cv=3,\n",
        "                                   scoring='neg_mean_squared_error',\n",
        "                                   random_state=5)\n",
        "\n",
        "random_search.fit(x_train, y_train)\n",
        "print(\"Best Parameters: \", random_search.best_params_)"
      ],
      "metadata": {
        "id": "5DsDzhTPRFYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters\n",
        "best_params = random_search.best_params_\n",
        "# best model\n",
        "model_best = xgb.XGBRegressor(**best_params)\n",
        "# train model\n",
        "model_best.fit(x_train, y_train)\n",
        "# forecasting ...\n",
        "y_pred = model_best.predict(x_test)"
      ],
      "metadata": {
        "id": "203Qm_wUhd5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5 - Data Evaluation"
      ],
      "metadata": {
        "id": "eIMnGDbdJKj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Model MSE: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"Best Model RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "4uns9NhNEBoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importance\n",
        "feature_importances = model_best.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display the feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': x_train.columns,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "importance_df.sort_values('Importance', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "Z4DEZAeDTN7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecasted_sales = data_test.copy()\n",
        "\n",
        "forecasted_sales['pred'] = np.round(y_pred, 0)\n",
        "forecasted_sales['error'] = np.round(forecasted_sales['pred'] - forecasted_sales['units'], 2)\n",
        "forecasted_sales = forecasted_sales.groupby(['weekly_date', 'store', 'item']).agg({\n",
        "    'units':'sum',\n",
        "    'lag_52':'sum',\n",
        "    'pred':'sum',\n",
        "    'error':'sum'\n",
        "})\n",
        "\n",
        "# forecasting sales by weekly_date and store columns\n",
        "forecasted_sales_by_store = forecasted_sales.groupby(['weekly_date', 'store']).agg({\n",
        "    'units':'sum',\n",
        "    'lag_52':'sum',\n",
        "    'pred':'sum'\n",
        "})\n",
        "\n",
        "# forecasting sales by weekly_date column\n",
        "forecasted_sales_by_week = forecasted_sales.groupby(['weekly_date']).agg({\n",
        "    'units':'sum',\n",
        "    'lag_52':'sum',\n",
        "    'pred':'sum'\n",
        "})\n",
        "\n",
        "# calculate pct_error column in the forecasted_sales dataframe\n",
        "forecasted_sales['pct_error'] = np.round(100 * ((forecasted_sales['pred']/forecasted_sales['units']) - 1), 2)\n",
        "\n",
        "# calculate error and pct_error columns in the forecasted_sales_by_store dataframe\n",
        "forecasted_sales_by_store['error'] = np.round(forecasted_sales_by_store['pred'] - forecasted_sales_by_store['units'], 2)\n",
        "forecasted_sales_by_store['pct_error'] = np.round( 100 * ((forecasted_sales_by_store['pred']/forecasted_sales_by_store['units']) - 1), 2)\n",
        "# calculate error and pct_error columns in the forecasted_sales_by_week dataframe\n",
        "forecasted_sales_by_week['error'] = np.round(forecasted_sales_by_week['pred'] - forecasted_sales_by_week['units'], 2)\n",
        "forecasted_sales_by_week['pct_error'] = np.round( 100 * ((forecasted_sales_by_week['pred']/forecasted_sales_by_week['units']) - 1), 2)"
      ],
      "metadata": {
        "id": "Sz3N4CMoSOMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------- Forecast Units Sold by Item -------')\n",
        "forecasted_sales_style = set_custom_style(forecasted_sales.head(5))\n",
        "forecasted_sales_style"
      ],
      "metadata": {
        "id": "hhsjTS8aIio3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "over = 30\n",
        "under = -30\n",
        "\n",
        "overestimated = forecasted_sales['pct_error'] <= over\n",
        "underestimated = forecasted_sales['pct_error'] >= under\n",
        "\n",
        "good_performance = forecasted_sales[(overestimated) & (underestimated)]\n",
        "bad_performance = forecasted_sales[~((overestimated) & (underestimated))]\n",
        "\n",
        "good_performance = good_performance.reset_index()\n",
        "good_performance = good_performance.groupby(['weekly_date', 'store']).agg({\n",
        "    'item':'nunique',\n",
        "    'units':'sum',\n",
        "    'lag_52':'sum',\n",
        "    'pred':'sum'\n",
        "})\n",
        "\n",
        "bad_performance = bad_performance.reset_index()\n",
        "bad_performance = bad_performance.groupby(['weekly_date', 'store']).agg({\n",
        "    'item':'nunique',\n",
        "    'units':'sum',\n",
        "    'lag_52':'sum',\n",
        "    'pred':'sum'\n",
        "})\n",
        "\n",
        "df_performance = good_performance.join(bad_performance, how='right', rsuffix='_2')\n",
        "\n",
        "df_performance.head(55)"
      ],
      "metadata": {
        "id": "UxW0a59xDRHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Forecast Units Sold by Store\n",
        "print('------- Forecast Units Sold by Store -------')\n",
        "print('------- SEP/24 -------')\n",
        "print('RMSE Store2: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store2'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store2'], 'pred'])), 2))\n",
        "print('RMSE Store3: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store3'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store3'], 'pred'])), 2))\n",
        "print('RMSE Store4: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store4'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store4'], 'pred'])), 2))\n",
        "print('RMSE Store5: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store5'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-09-01':'2024-09-30',\n",
        "                                                                                                              'Store5'], 'pred'])), 2))\n",
        "print('------- OCT/24 -------')\n",
        "print('RMSE Store2: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store2'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store2'], 'pred'])), 2))\n",
        "print('RMSE Store3: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store3'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store3'], 'pred'])), 2))\n",
        "print('RMSE Store4: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store4'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store4'], 'pred'])), 2))\n",
        "print('RMSE Store5: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store5'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-10-01':'2024-10-31',\n",
        "                                                                                                              'Store5'], 'pred'])), 2))\n",
        "print('------- NOV/24 -------')\n",
        "print('RMSE Store2: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store2'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store2'], 'pred'])), 2))\n",
        "print('RMSE Store3: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store3'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store3'], 'pred'])), 2))\n",
        "print('RMSE Store4: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store4'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store4'], 'pred'])), 2))\n",
        "print('RMSE Store5: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store5'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-11-01':'2024-11-30',\n",
        "                                                                                                              'Store5'], 'pred'])), 2))\n",
        "print('------- DIC/24 -------')\n",
        "print('RMSE Store2: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store2'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store2'], 'pred'])), 2))\n",
        "print('RMSE Store3: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store3'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store3'], 'pred'])), 2))\n",
        "print('RMSE Store4: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store4'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store4'], 'pred'])), 2))\n",
        "print('RMSE Store5: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store5'], 'units'],\n",
        "                                                    forecasted_sales_by_store.loc[pd.IndexSlice['2024-12-01':'2024-12-31',\n",
        "                                                                                                              'Store5'], 'pred'])), 2))\n",
        "forecasted_sales_by_store_style = set_custom_style(forecasted_sales_by_store['2024-11-01':'2024-11-30'].head(5))\n",
        "forecasted_sales_by_store_style\n"
      ],
      "metadata": {
        "id": "4nRJaE3rMXth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_weekly_sales_per_month = forecasted_sales_by_store.reset_index()\n",
        "avg_weekly_sales_per_month['weekly_date'] = pd.to_datetime(avg_weekly_sales_per_month['weekly_date'])\n",
        "avg_weekly_sales_per_month['month'] = avg_weekly_sales_per_month['weekly_date'].dt.month\n",
        "\n",
        "avg_weekly_sales_per_month = avg_weekly_sales_per_month.groupby(['store', 'month']).agg({\n",
        "    'units':'mean'\n",
        "})\n",
        "\n",
        "avg_weekly_sales_per_month.head()"
      ],
      "metadata": {
        "id": "9nwsow3ejqfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------- Forecast Units Sold by Week -------')\n",
        "# print('RMSE SEP/24: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_week['2024-09-01':'2024-09-30'].units,\n",
        "#                                                     forecasted_sales_by_week['2024-09-01':'2024-09-30'].pred)), 2))\n",
        "# print('RMSE OCT/24: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_week['2024-10-01':'2024-10-31'].units,\n",
        "#                                                     forecasted_sales_by_week['2024-10-01':'2024-10-31'].pred)), 2))\n",
        "print('RMSE NOV/24: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_week['2024-11-01':'2024-11-30'].units,\n",
        "                                                    forecasted_sales_by_week['2024-11-01':'2024-11-30'].pred)), 2))\n",
        "print('RMSE DIC/24: ', np.round(np.sqrt(mean_squared_error(forecasted_sales_by_week['2024-12-01':'2024-12-31'].units,\n",
        "                                                    forecasted_sales_by_week['2024-12-01':'2024-12-31'].pred)), 2))\n",
        "\n",
        "forecasted_sales_by_week_style = set_custom_style(forecasted_sales_by_week.head(15))\n",
        "forecasted_sales_by_week_style"
      ],
      "metadata": {
        "id": "WCu6NtYdMeSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(df):\n",
        "  df['units'].plot(color='blue', label='units')\n",
        "  df['pred'].plot(color='red', label='forecast')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Rz-2nrDMCEVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(forecasted_sales_by_week['2024-11-01':'2024-12-31'])"
      ],
      "metadata": {
        "id": "14fG02ZQS2lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6 - Next Steps"
      ],
      "metadata": {
        "id": "81c3Ey-9JTfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_by_store_flt = sales_by_store[sales_by_store['store'] == 'Store4']\n",
        "\n",
        "# Apply Exponential Moving Average\n",
        "sales_by_store_flt['ema'] = sales_by_store_flt['units'].ewm(span=5, adjust=False).mean()\n",
        "\n",
        "# Plot the smoothed time series\n",
        "sales_by_store_flt[['units', 'ema']].plot(figsize=(10, 6), title='Time Series with EMA')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "# sales_by_store_temp = sales_by_store[sales_by_store['store'] == 'Store1']\n",
        "# sales_by_store_temp = sales_by_store_temp[\"2025-10-01\":\"2025-12-28\"]\n",
        "\n",
        "# ax.plot(sales_by_store_temp.index, sales_by_store_temp['units'])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "-LdDnqFrpoze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Step 0 - Getting Started\n",
        "- Import Libraries\n",
        "- Load Data\n",
        "\n",
        "Step 1 - Data Cleaning\n",
        "- Change Wide to Long Format\n",
        "- Change Data Types\n",
        "- Map Categorical Variables To Weekly Dates\n",
        "\n",
        "Step 2 - Data Understanding\n",
        "- Stats\n",
        "- Plot ACF\n",
        "\n",
        "Step 3 - Feature Engineering\n",
        "- Lags\n",
        "- Seasonal Pattern\n",
        "- Month Encoded\n",
        "- Store Encoded\n",
        "\n",
        "Step 4 - Data Modeling\n",
        "- Split Train and Test\n",
        "- GridSearch\n",
        "- Model\n",
        "\n",
        "Step 5 - Data Evaluation\n",
        "- RMSE\n",
        "\n",
        "Step 6 - Next Steps\n",
        "-\n",
        "'''"
      ],
      "metadata": {
        "id": "5lGe9sASJhcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}